\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[margin=1cm]{geometry}
\usepackage{polski}
\usepackage{titling}
\usepackage{romannum}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathdots}
\usepackage{fullpage}
\usepackage{gensymb}
\usepackage{MnSymbol}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{dsfont}
\usepackage{url}

\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\Z{\mathbb{Z}}
\def\Q{\mathbb{Q}}
\def\N{\mathbb{N}}
\def\Rn{\mathbb{R}^n}
\def\E{\mathcal{E}}
\def\B{\mathcal{B}}
\def\1{\mathds{1}}
\def\nor{\trianglelefteq}
\def\ker{\operatorname{ker}}
\def\gengru#1{\langle\,#1 \,\rangle}
\def\ch{\blacktriangleleft}
\def\arr{\longrightarrow}
\def\Abs#1{\left\vert#1\right\vert}
\def\rk{\operatorname{rank}}
\def\lin{\operatorname{lin}}
\def\af{\operatorname{af}}
\def\dim{\operatorname{dim}}
\def\ker{\operatorname{ker}}
\def\im{\operatorname{im}}
\def\tr{\operatorname{tr}}
\def\Hom{\operatorname{Hom}}
\def\Aut{\operatorname{Aut}}
\def\id{\triangleleft}
\def\iif{\operatorname{if}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\def\normsign{\|\cdot\|}
\newcommand{\series}[3]{\sum_{#1}^{#2}#3}

\newtheorem{problem}{Problem}
\newtheorem{definicja}{Definicja}

\setlength{\droptitle}{-2cm}
\title{Optymalna strategia podawania leku}
\author{Tomasz Kanas}

\begin{document}
\pagenumbering{gobble}
\maketitle

\section{Sformułowanie problemu}
Celem pracy jest znalezienie strategii podawania leku przy leczeniu nowotworu, pozwalającej osiągnąć możliwie największą skuteczność terapii. W tym celu skorzystamy z modelu przedstawionego w pracy \cite{BBF-manuscript} (zobacz też \cite{BBF2016}, \cite{BBF2019} gdzie przedstawiono podobne zagadnienia). Model ten przedstawia rozwój nowotworu w czasie w zależności od dawkowania leku, $g(t)$, za pomocą równania różniczkowego:
\begin{equation} \label{ode}
  \begin{aligned} 
    V_1'(t) &= \lambda_1V_1F\left(\frac{V_1 + \alpha_{12}V_2}{K}\right) - \beta_1V_1g(t), \\
    V_2'(t) &= \lambda_2V_2F\left(\frac{V_2 + \alpha_{21}V_1}{K}\right) - \beta_2V_2g(t), \\
    K'(t) &= -\mu K + (V_1+V_2) - d{(V_1 + V_2)}^{2/3}K - \beta K g(t) \\
  \end{aligned}
\end{equation}
dla $t \in [0, T]$, z warunkami początkowymi
\begin{equation} \label{ode-start}
   V_1(0) = V_{10},\ V_2(0) = V_{20},\ K(0) = K_0
\end{equation}
gdzie $F(x) = -\ln(x)$, $ 0 \le g(t) \le g_{\max}$, oraz
\[\lambda_1, \lambda_2, \alpha_{12}, \alpha_{21}, \beta_1, \beta_2, \beta, \mu, d, V_{10}, V_{20}, K_0 \]
są zadanymi nieujemnymi parametrami.

Funkcja $V_1(t)$ modeluje liczbę komórek guza podatnych na lek w momencie $t$, $V_2(t)$ liczbę komórek guza odpornych na lek, a $K(t)$ jest parametrem nazwanym w pracy ,,unaczynieniem''. Zauważmy, że rozwiązania $V_1, V_2, K$ zależą od wyboru funkcji $g$ którą nazywamy sterowaniem. W tym modelu wartość $g(t)$ ma interpretację jako wielkość dawki leku w czasie $t$.

Zgodnie z \cite{BBF-manuscript}, zadanie polega na znalezieniu funkcji $g: [0, T] \to [0, g_{\max}]$ takiej, że funkcje $V_1, V_2, K: [0, T] \to (0, \infty)$ spełniające (\ref{ode}) minimalizują funkcjonał:
\begin{equation} \label{objf}
  J(g, V_1, V_2, K) = \int_0^T V_1(t) + V_2(t)dt + \omega\int_0^T G\left(\frac{V_2(t) - V_1(t)}{\epsilon}\right) dt
\end{equation}
gdzie
\begin{equation*}
  G(x) = \frac{1+\tanh(x)}{2} \quad
  \omega, \epsilon > 0 
\end{equation*}

Problem ten w literaturze nazywa się problemem optymalnego sterowania.

\subsection{Problem wyjściowy}
Zdefiniujmy teraz formalnie problem oraz uprośćmy notację.

\begin{problem}\label{problem}
  Znaleźć funkcję kawałkami ciągłą
  \[g: [0, T] \to [0, g_{\max}],\]
  i funkcję
  \[y = {(y_1, y_2, y_3)}^T: [0,T] \to {(0, \infty)}^3,\]
  spełniającą równanie różniczkowe:
  \begin{equation}\label{odesim}
    \begin{aligned}
      \dot{y}(t) &= f(t, y, g), \\
      y(0) &= y_0 = {(y_{10}, y_{20}, y_{30})}^T,
    \end{aligned}
  \end{equation}
  minimalizujące funkcjonał
  \begin{equation}\label{objfsim}
    J(g, y) = \int_0^T y_1(t) + y_2(t)dt + \omega\int_0^T G\left(\frac{y_2(t) - y_1(t)}{\epsilon}\right) dt,
  \end{equation}
  gdzie $f = {(f_1, f_2, f_3)}^T$ jest określone wzorem
  \begin{equation}\label{dynamicsim}
    \begin{aligned}
      f_1(t, y, g) &= \lambda_1y_1F\left(\frac{y_1 + \alpha_{12}y_2}{y_3}\right) - \beta_1y_1g(t), \\
      f_2(t, y, g) &= \lambda_2y_2F\left(\frac{y_2 + \alpha_{21}y_1}{y_3}\right) - \beta_2y_2g(t), \\
      f_3(t, y, g) &= -\mu y_3 + (y_1+y_2) - d{(y_1 + y_2)}^{2/3}y_3 - \beta y_3 g(t). \\
    \end{aligned}
  \end{equation}
\end{problem}

Przez funkcję kawałkami ciągłą określoną na odcinku rozumiemy funkcję o skończonej liczbie punktów nieciągłości. Jako, że o funkcji $f$ zakładamy tylko kawałkami ciągłość, należy doprecyzować co rozumiemy przez (\ref{odesim}). Załóżmy, że punktami nieciągłości $f(t,y,g): \R^5 \to \R$ są $t = \xi_1,\ \ldots,\ \xi_n \in \R$, wtedy (\ref{odesim}) oznacza sekwencję równań różniczkowych postaci
\begin{equation}\label{nonconode}
  \begin{aligned}
    \dot{y}|_{(\xi_i, \xi_{i+1})}(t) &= f|_{(\xi_i, \xi_{i+1})}(t, y, g)\\
    y(\xi_i) &= \lim_{t\to \xi_i^-}y(t)
  \end{aligned}
  \quad \text{ gdzie } i \in \{0,\ldots, n\},\ \xi_0 = 0,\ \xi_{n+1}=T
\end{equation}

Zwróćmy jeszcze uwagę na fakt, że funkcja $F(x) = -\ln(x)$ posiada osobliwość w 0, więc prawa strona (\ref{dynamicsim}) nie jest dobrze zdefiniowana dla $y_1(t) = y_2(t) = 0$, a obliczenia w których argumenty $F$ są bliskie 0 mogą być obarczone dużymi błędami numerycznymi. Podobnie we wzorze (\ref{dynamicsim}) występuje dzielenie przez $y_3$, więc dla $y_3(t) = 0$ prawa strona (\ref{odesim}) także nie jest dobrze określone.

\subsection{Problem przybliżony}\label{simp_problem_subsec}
Wyznaczenie rozwiązania problemu optymalnego sterowania w postaci jawnego wzoru rzadko kiedy jest możliwe. Z tego powodu zdecydujemy się na szukanie rozwiązania przybliżonego.

Rozwiązanie problemu \ref{problem} przybliżymy rozwiązaniem pewnego problemu optymalizacji skończenie wymiarowej. W tym celu ustalimy siatkę dyskretyzacji przedziału $[0, T]$:
\begin{equation}
  0 = t_0 < t_1 < \cdots < t_{n-1} < t_n = T
\end{equation}
Możemy teraz przybliżać sterowanie $g$ za pomocą splajnu opartego na punktach $t_{i}$. Dla prostoty ograniczymy się do splajnów stopnia 0 i 1. Ostatecznie przybliżone sterowanie $\hat{g}$ ma postać:
\begin{gather}  
    \hat{g}(t) = g_i \text{ gdy } t \in [t_{i}, t_{i + 1}) \quad \text{(sterowanie kawałkami stałe)} \label{control_1}\\
    \nonumber \text{albo} \\
    \hat{g}(t) = \frac{(t_{i+1} - t)g_i + (t - t_i)g_{i+1}}{t_{i+1} - t_i} \text{ gdy } t \in [t_i, t_{i+1}) \quad \text{(sterowanie kawałkami liniowe)} \label{control_2}
\end{gather}
i jest jednoznacznie zdefiniowane przez wartości $g_i \simeq g(t_i)$ dla $i = 0,\ldots, n$. Te wartości będą optymalizowanymi zmiennymi.

Korzystając z przybliżonej funkcji sterowania, na każdym odcinku $[t_n, t_{n+1}]$ przybliżymy rozwiązanie $y$ równania różniczkowego (\ref{odesim}). Użyjemy do tego $M$ kroków metody Rungego-Kutty rzędu $r$ ze stałym krokiem długości $h = \frac{t_{n+1} - t_n}{M}$, wtedy przybliżone rozwiązanie $\hat{y}(t) \simeq y(t)$ w punkcie $t = t_n + (m + 1)h$ dla $m = 0,\ldots, M$  wyraża się przez:
\begin{equation} \label{rk}
  \begin{split}
    &k_1 = f(t_n + mh, \hat{y}(t_n + mh), \hat{g}), \\
    &k_l = f(t_n + c_l h, \hat{y}(t_n + mh) + h \sum_{i = 1}^{l-1} a_{li}k_i, \hat{g}),\quad l = 2,\ldots, r \\
    &\hat{y}(t_n + (m+1)h) = \hat{y}(t_n + mh) + h \sum_{i = 1}^r b_i k_i,
  \end{split}
\end{equation}
gdzie $c_l, a_{li}, b_i$ są stałymi zależnymi od wybranej metody.

Zostało już tylko przybliżyć funkcjonał celu (\ref{objfsim}). Zapiszmy go w postaci
\begin{equation} \label{objf-sim}
  J(y) = \int_0^T j(y(t)) dt,
\end{equation}
gdzie
\begin{equation}
  j(y) = y_1 + y_2 + \omega G\left(\frac{y_2 - y_1}{\epsilon} \right).
\end{equation}
Wtedy ogólny wzór na kwadraturę ze stałym krokiem $h$ przybliżającą (\ref{objf-sim}) to
\begin{equation} \label{quad}
  Q(\hat{y}) = h\sum_{i = 0}^N \alpha_i j(\hat{y}(ih)),
\end{equation}
gdzie $N = \frac{T}{h}$, a $\alpha_i$ są stałymi zależnymi od wybranej kwadratury.

Zatem możemy zdefiniować przybliżoną funkcję celu jako funkcję $g_0,\ldots,g_n$:
\begin{equation}
  \hat{J}(g_0,\ldots, g_n) = Q(\hat{y}),
\end{equation}
ponieważ $\hat{y}$ jest jednoznacznie wyznaczony przez $\hat{g}$ za pomocą (\ref{rk}), a $\hat{g}$ jest wyznaczone jednoznacznie przez $g_0,\ldots,g_n$. Podsumowując, problem przybliżony to:
\begin{problem}\label{problemapprox}
  Znaleźć $g_0,\ldots, g_n$ minimalizujące
\begin{equation}\label{nlp}
  \hat{J}(g_0,\ldots, g_n),
\end{equation}
i spełniające
\begin{equation}\label{nlp_cons}
  \forall_{i \in \{0,\ldots,n\}} 0 \le g_i \le g_{\max}.
\end{equation}
\end{problem}

Jest to problem optymalizacji nieliniowej z ograniczeniami i istnieją implementacje metod pozwalających uzyskać przybliżone rozwiązanie tego problemu. To podejście do numerycznego problemu optymalnego nazywa się ,,direct single shooting'' i występuje np. w~\cite{diehl} i~\cite{rao-methods}.

\subsection{Alternatywne podejście}

Innym popularnym podejściem jest ,,direct collocation''. W tym podejściu zaczyna się, tak samo jak powyżej, od dyskretyzacji czasu:
\begin{equation}
  0 = t_0 < t_1 < \ldots < t_n = T.
\end{equation}
Następnie zarówno sterowanie jak i stan układu przybliża się splajnem opartym na punktach $t_i$. Dzięki temu sterowanie jest jednoznacznie wyznaczone przez wartości $g_i = \hat{g}(t_i)$, natomiast stan układu przez wartości $y_i = \hat{y}(t_i)$. Celem jest, tak samo jak powyżej, sprowadzenie problemu do problemu optymalizacji nieliniowej z ograniczeniami. Aby móc to zrobić należy znaleźć warunki jakie wartości $y_i$ muszą spełniać, aby układ spełniał w przybliżeniu równanie
\begin{equation}\label{ode-alternative}
  \dot{y}(t) = f(t,y(t),g(t)).
\end{equation}
Aby znaleźć te warunki przybliża się całkę z powyższego równania za pomocą pewnej kwadratury. Dla przykładu ustalmy kwadraturę trapezową. Wtedy dostajemy równanie przybliżone
\begin{equation}
  \int_{t_i}^{t_{i+1}} \dot{y}(t)dt = \int_{t_i}^{t_{i+1}} f(t,y(t),g(t))dt
\end{equation}
\begin{equation}
  y_{i+1} - y_{i} \simeq \frac{1}{2}(t_{i+1}-t_i)(f(t_{i+1}, y_{i+1}, g(t_{i+1})) - f(t_i, y_i, g(t_i))).
\end{equation}
Powyższy wzór dodaje się do ograniczeń optymalizatora jako ograniczenie równościowe. W ten sposób RRZ (\ref{ode-alternative}) zostaje w przybliżeniu wymuszone w rozwiązaniu.

Ograniczenia występujące w sformułowaniu oryginalnego problemu można zwykle bez problemu przekształcić na ograniczenia na $g_i$ oraz $y_i$. Przybliżony funkcjonał celu definiuje się, jako numeryczne przybliżenie oryginalnego funkcjonału celu zastosowane do przybliżonego stanu $\hat{y}$ i sterowania $\hat{g}$.

Podejście to jest dokładnie opisane w~\cite{Kelly}, występuje też w~\cite{diehl} i~\cite{rao-methods}.

\subsection{Plan rozwiązania}
Aby obliczyć wynik problemu przybliżonego zdefiniowanego w rozdz.~\ref{simp_problem_subsec} zaimplementujemy przejście od problemu optymalnego sterowania do problemu optymalizacji nieliniowej z ograniczeniami. W tym celu skorzystamy ze środowiska MATLAB/Octave i dostarczonego w nim optymalizatora (FMINICON). Aby poprawić złożoność czasową optymalizacji i tym samym umożliwić stosowanie gęstszej siatki dyskretyzacji, obliczymy gradient przybliżonej funkcji celu. Będziemy też musieli znaleźć odpowiednią siatkę dyskretyzacji i punkt startowy dla optymalizatora.

\section{Implementacja}
Optymalizator FMINICON wymaga dostarczenia funkcji do optymalizowania, czyli w naszym przypadku funkcji $\hat{J}$, oraz ograniczeń, czyli w przypadku metody ,,direct single shooting'' jedynie (\ref{nlp_cons}). Domyślnie optymalizator wyznacza gradient za pomocą różnic skończonych, co jest kosztowne, gdyż wymaga uruchomienia funkcji celu liniowo wiele razy względem liczby parametrów. Aby poprawić wydajność optymalizacji zaimplementujemy liczenie gradientu przybliżonej funkcji celu ze względu na parametry $g_0,\ldots, g_n$.

Zauważmy, że znalezienie dobrego wyniku będzie wymagało zapewne wielokrotnego wywołania naszej funkcji celu przez optymalizator, więc zależy nam aby funkcja celu liczyła się możliwie szybko. Lepsza wydajnościowo implementacja pozwoli też na większe zagęszczenie siatki dyskretyzacji i tym samym wzrost dokładności aproksymacji.

Jedną z praktyk pozwalającą poprawić wydajność programów w środowiskach MATLAB i Octave jest tak zwana wektoryzacja. Polega ona na zastępowaniu pętli operacjami na wektorach. Korzysta to z faktu, że wiele funkcji w tych środowiskach można wywołać z wektorem parametrów, zamiast pojedynczego parametru i zwracają one wtedy wektor wyników, oraz wykonują się znacznie szybciej niż gdyby wywołać je wielokrotnie w pętli. Z tego powodu będziemy korzystać z tej techniki gdzie to tylko możliwe.

Aby sprowadzić problem optymalnego sterowania do problemu optymalizacji nieliniowej musimy obliczyć przybliżone sterowanie (\ref{control_1}) lub (\ref{control_2}), przybliżyć rozwiązanie równania różniczkowego (\ref{rk}) a następnie za pomocą uzyskanego rozwiązania obliczyć kwadraturę (\ref{quad}) przybliżającą funkcję celu (\ref{objf}). Ponadto chcemy obliczyć gradient funkcji celu, co będzie wymagało policzenia pochodnej każdego z wymienionych wzorów względem parametrów $g_i$.

\subsection{Sterowanie}\label{subsec_sterowanie}
Jedynym problemem przy implementacji przybliżonego sterowania (\ref{control_1}) lub (\ref{control_2}) jest znalezienie indeksu $i$ takiego, że $t \in [t_{i-1}, t_i)$. Użyjemy do tego funkcji $lookup$, która wydajnie znajduje żądany indeks korzystając z wyszukiwania binarnego.

Aby policzyć gradient przybliżonego sterowania $\hat{g}$ ze względu na parametry $g_1,\ldots,g_n$ należy zróżniczkować równanie (\ref{control_1}) lub (\ref{control_2}):

\begin{gather}
  \frac{\partial \hat{g}}{\partial g_i}(t) = \begin{cases} 1 \text{ gdy } t \in [t_{i-1}, t_i) \\ 0 \text{ w.p.p.} \end{cases} \label{dcontrol_1}\\
  \nonumber \text{albo}\\
  \frac{\partial \hat{g}}{\partial g_i}(t) = \begin{cases} \frac{t_i - t}{t_i - t_{i-1}} \text{ gdy } t \in [t_{i-1}, t_i) \\ \frac{t - t_i}{t_{i+1} - t_i} \text{ gdy } t \in [t_{i}, t_{i+1}) \\ 0 \text{ w.p.p.} \end{cases} \label{dcontrol_2}
\end{gather}

Implementacja powyższych wzorów jest standardowa, znajdowanie odpowiedniego indeksu $i$ odbywa się tak samo, jak przy liczeniu wartości przybliżonego sterowania.

Zarówno funkcja $lookup$ jak i pozostałe operacje wykorzystywane do policzenia przybliżonego sterowania i jego gradientu są zwektoryzowane, w szczególności środowiska MATLAB i Octave umożliwiają wektorowe indeksowanie, więc nasza implementacja sterowania i gradientu też jest zwektoryzowana.

\subsection{Równanie różniczkowe}\label{subsec_rrz}
Aby przybliżyć rozwiązanie równania (\ref{ode}) należy zaimplementować funkcję $f(t,y,g)$, a następnie bezpośrednio zaimplementować odpowiednią metodę Rungego-Kutty (\ref{rk}). Wzory te implementuje się bezpośrednio.

Liczenie pochodnych $\frac{\partial \hat{y}}{\partial g_i}$ polega na zróżniczkowaniu wzorów (\ref{rk}):
\begin{gather}
    \frac{\partial k_1}{\partial g_i} = D_f \cdot \frac{\partial \hat{y}}{\partial g_i}(t_n + mh) + \frac{\partial f}{\partial g_i}(t_n + mh, \hat{y}(t_n + mh), \hat{g}) \nonumber \\
    \frac{\partial k_l}{\partial g_i}  = D_f \cdot \left(\frac{\partial \hat{y}}{\partial g_i}(t_n + mh) + h\sum_{j=1}^{l-1} a_{lj}\frac{\partial k_i}{\partial g_j} \right) + \frac{\partial f}{\partial g_i}(t_n + mh, \hat{y}(t_n + mh), \hat{g})  \label{drk}\\
    \frac{\partial \hat{y}}{\partial g_i}(t_n + (m+1)h) = \frac{\partial \hat{y}}{\partial g_i}(t_n + mh) + h\sum_{j=1}^r b_j \frac{\partial k_j}{\partial g_i} \nonumber
\end{gather}
gdzie
\begin{equation} \label{Df}
  D_f = {\left[\frac{\partial f_i}{\partial y_j}\right]}_{i,j = 1,\ldots, 3} (t_n + ah, \hat{y}(t_n + mh), \hat{g})
\end{equation}
Wzory na elementy macierzy $D_f$ pominiemy, liczy się je i implementuje standardowo.

Nasza implementacja umożliwia też przekazanie wektora punktów w czasie jako argumentu. W takim przypadku w trakcie iteracji będzie spamiętywać wyliczone wartości w tych punktach. Dla wygody założymy, że punkty podane będą w kolejności rosnącej, oraz odległości między sąsiednimi punktami będą podzielne przez długość kroku $h$.

\subsection{Funkcja celu}
Przybliżoną funkcję celu (\ref{quad}) można zaimplementować za pomocą iloczynu skalarnego:
\begin{equation}
  Q(\hat{y}) = {\left(h(\alpha_0),\ldots,h(\alpha_N)\right)}^T \cdot {j(\hat{y}(0, h, 2h, \ldots, T))}
\end{equation}

W implementacji w Octave korzystamy ze zwektoryzowanej implementacji funkcji $\hat{y}$. Implementacja funkcji $j$ też jest zwektoryzowana, ponieważ środowisko dostarcza nam zwektoryzowaną funkcję $\tanh$, a pozostałe operacje wektoryzują się naturalnie.

Gradient funkcji celu możemy zaimplementować jako mnożenie wektora przez macierz:
\begin{equation}
  {\left[\frac{\partial J}{\partial g_i}\right]}_{i = 0, \ldots n} = {\left(h(\alpha_0),\ldots,h(\alpha_N)\right)}^T \cdot {\left[\frac{\partial j(\hat{y}(hi))}{\partial g_k}\right]}_{i = 0, \ldots N, k = 1, \ldots n}
\end{equation}
gdzie
\begin{equation}
  \frac{\partial j(y(t))}{\partial g_i} = \frac{\partial y_1(t)}{\partial g_i} + \frac{\partial y_2(t)}{\partial g_i} + \omega G'\left(\frac{y_2(t) - y_1(t)}{\epsilon}\right)\frac{\frac{\partial y_2(t)}{\partial g_i} - \frac{\partial y_1(t)}{\partial g_i}}{\epsilon},\quad G'(x) = \frac{1}{2\cosh^2(x)}
\end{equation}
\section{Eksperymenty}
W eksperymentach, do przybliżania rozwiązania równania (\ref{odesim}), będziemy korzystać z metody Rungego-Kutty 4-tego rzędu, ponieważ daje ona dobrą dokładność, a liczenie wartości funkcji $f$ nie jest zbyt kosztowne. Wartości stałych $c_l$, $a_{li}$, $b_i$ z wzoru (\ref{rk}) podane na tabeli Butchera:
\begin{equation}\label{butcher}
  \begin{array}
    {c|cccc}
    0\\
    \frac{1}{2} & \frac{1}{2}\\
    \frac{1}{2} &0 &\frac{1}{2} \\
    1& 0& 0& 1\\
    \hline{}
    & \frac{1}{6} &\frac{1}{3} &\frac{1}{3} &\frac{1}{6} 
  \end{array}
\end{equation}
Do przybliżania funkcjonału celu (\ref{objf}) użyjemy kwadratury trapezów. Kwadratura (\ref{quad}) wyraża się więc przez:
\begin{equation} \label{trapezoidal}
  Q(\hat{y}) = h\left(\frac{1}{2}(j(\hat{y}(0)) + j(\hat{y}(T))) + \sum_{i=1}^{N-1} j(\hat{y}(ih))\right)
\end{equation}

\subsection{Zbiór testowy}
Opiszemy teraz szeroki zbiór testowy, dobrany w taki sposób, aby móc zbadać wpływ różnych czynników na ostateczny wynik optymalizacji.
\subsubsection{Zestawy parametrów}
Użyjemy wartości parametrów podanych w wyjściowej pracy~\cite{BBF-manuscript}:
\begin{align*}
  t_0 &= 0          & \lambda_1 &= 0.192 & g_{\max} &= 3    \\
  T &= 200          & \lambda_2 &= 0.192 & \epsilon &= 0.01 \\
  V_{10} &= 20      & \beta_1 &= 0.15    & d &= 0.00873     \\
  V_{20} &= 280     & \beta_2 &= 0.1     & \mu &= 0         \\
  K_0 &= 650        & \beta &= 0.05      &       &          \\
\end{align*}
Wartości parametrów $\alpha_{12},\ \alpha_{21},\ \omega$ nie zostały ustalone w pracy, jedyne co jest ustalone to
\[ \alpha_{12} < \alpha_{21}\quad 0 < \omega \le 2000 \]
więc zbadamy problem dla 2 arbitralnie wybranych zestawów wartości tych parametrów (oznaczamy jako ,,Parametry'' w tabelach z wynikami):
\begin{itemize}
\item{(CC)} $\quad \alpha_{12} = 0.1 \quad \alpha_{21} = 0.15 \quad \omega = 1000$
\item{(DC)} $\quad \alpha_{12} = 0.5 \quad \alpha_{21} = 0.75 \quad \omega = 2000$ 
\end{itemize}
\subsubsection{Algorytmy}
Do eksperymentów użyte zostało środowisko Octave. Optymalizator FMINICON na tym środowisku umożliwia użycie jednego z dwóch algorytmów do optymalizacji nieliniowej:
%TODO: krótkie wyjaśnienie co to za algorytmy
\begin{itemize}
\item{\it lm\_feasible\/} oznaczany w skrócie {\it lm\/}
\item{\it sqp\/}
\end{itemize}
Jedną z różnic między tymi algorytmami jest to, że {\it lm\_feasable\/} zachowuje ograniczenia w trakcie optymalizacji, natomiast {\it sqp\/} wymusza ograniczenia jedynie na koniec procesu optymalizacji. W eksperymentach przetestowane zostały oba z tych algorytmów.
\subsubsection{Metody dyskretyzacji}
Do dyskretyzcji sterowania użyjemy dwóch metod (oznaczane ,,aproks.'' tabelach z wynikami):
\begin{itemize}
\item{$P_0$:} wykorzystująca splajny kawałkami stałe, zob. (\ref{dcontrol_1})
\item{$P_1$:} wykorzystująca splajny kawałkami liniowe, zob. (\ref{dcontrol_2})
\end{itemize}
Splajny te opierają się na siatce która, na użytek eksperymentu, może być jednego z trzech rodzajów (oznaczane ,,siatka'' w tabelach z wynikami):
\begin{itemize}
\item{$S_{\tau}$:} jednorodna, z krokiem $\tau$, więc $t_n = \tau n$. Ograniczymy się do $\tau \in \{0.1, 0.5, 1, 4\}$.
\item{$N_{sr}$: Niejednorodna, gęstsza w środku} $t_n = \begin{cases}
    n \iif n \le 25 \\
    25 + 0.1\cdot(n-25) \iif 25 < n \le 525 \\
    75 + (n - 525) \iif n > 525
  \end{cases}$
\item{$N_{kon}$: Niejednorodna, gęstsza na końcach} $t_n = \begin{cases}
    0.5\cdot n \iif n \le 100 \\
    50 + (n - 50) \iif 100 < n \le 200 \\
    150 + 0.5\cdot (n - 200) \iif n > 200
  \end{cases}$
\end{itemize}
\subsubsection{Krok dyskretyzacji $h$ metody R-K rozwiązania (\ref{odesim})}
Ograniczymy się do $h \in \{0.02, 0.1, 0.5\}$.
\subsubsection{Sterowania startowe}
\begin{itemize}
\item $g_0\equiv 0$
\item $g_{3} \equiv g_{\max} = 3$
\item $g_{\alpha,\beta} = \alpha \cdot \1_{[\beta, T]}$. Ograniczymy się do: $g_{0.4,42.5},\ g_{0.55,42.5}$.
\item $\mathfrak{g} = 3 \cdot \1_{[0,10]} + 0.5 \cdot \1_{[50, T]}$
\end{itemize}
Oznaczane ,,start'' w tabelach z wynikami.

\subsection{Wyniki eksperymentów}
Jako, że powyższy zbiór jest duży, wykorzystamy jedynie niektóre testy. Przeprowadzimy kilka eksperymentów, każdy eksperyment będzie przeprowadzony na podzbiorze zbioru testowego, wybranym tak, aby zaprezentować wpływ konkretnego parametru na wyniki.

Wyniki eksperymentów będziemy oceniać na podstawie trzech wartości: wartości przybliżonego funkcjonału celu $\hat{J}$, liczby iteracji optymalizatora (oznaczaną przez ,,iter''), oraz liczbę wywołań funkcjonału celu w trakcie optymalizacji (oznaczaną przez $\#\hat{J}$).

Wartości funkcji celu są duże, więc dla zwiększenia czytelności będziemy podawać wartości dla $10^{-5}\hat{J}$ zaokrąglone do 2 miejsc po przecinku.
\subsubsection{Test poprawności liczenia gradientu}
Pierwszy eksperyment ma na celu zaprezentowanie poprawności implementacji obliczania gradientu funkcji celu. Aby to sprawdzić porównamy naszą implementację, z domyślną implementacją przybliżającą gradient za pomocą różnic skończonych dostępną w FMINICON.\ Obliczanie wyników metodą domyślną wymaga wiele czasu, więc eksperyment obejmie tylko jeden przypadek, opisany na Tabeli~\ref{test_tbl}. Celem tego eksperymentu jest sprawdzenie poprawności implementacji, więc ograniczymy liczbę iteracji optymalizatora do 20.
\begin{table}[h]
  \begin{center}
    \begin{tabular}{|p{1.7cm}|c|c|c|c|c|c|c|c|c|}
      \hline
      Gradient & Parametry & algorytm & aproks. & siatka & $h$ & start & $\hat{J}$ & iter & $\#\hat{J}$ \\
      \hline
      FD & (CC) & {\it lm\/} & $P_0$ & $S_4$ & 0.1 & $g_0$ & $3.26$ & 20 & 38 \\
      \hline
      wg. rozdz. \ref{subsec_sterowanie}, \ref{subsec_rrz} & (CC) & {\it lm\/} & $P_0$ & $S_4$ & 0.1 & $g_0$ & $3.25$ & 20 & 37 \\
      \hline
    \end{tabular}
    \caption{Test implementacji gradientu}\label{test_tbl}
  \end{center}
\end{table}

\begin{figure}[h]
  \begin{subfigure}{.5\textwidth}
    \caption{Rozwiązanie przy użyciu różnic skończonych}\label{nograd_sol}
    \includegraphics[width=\textwidth]{../plots/plot_nograd}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \caption{Rozwiązanie z liczeniem gradientu}\label{test_sol}
    \includegraphics[width=\textwidth]{../plots/plot_test}
  \end{subfigure}%
  \caption{Rozwiązania dla przypadku testowego}\label{test_nograd_sol}
\end{figure}
Rozwiązania uzyskane obiema metodami są bardzo podobne, o czym świadczą wyniki zaprezentowane na Tabeli~\ref{test_tbl} i Rysunku~\ref{test_nograd_sol}. Ponadto nasza implementacja osiągnęła minimalnie lepszy wynik.

Aby zyskać jeszcze większą pewność o poprawności naszej implementacji policzymy gradient $\hat{J}$ względem parametrów $g_i$, w punkcie będącym sterowaniem zaprezentowanym na wykresie~(\ref{test_sol}). Porównamy gradient $G$ obliczony przy użyciu naszej implementacji, oraz gradient $G_\tau$ uzyskany za pomocą metody różnic skończonych dla różnych wartości kroku różnic skończonych
\[\tau \in \{10^{-3},\ldots,10^{-10}\}.\]
Następnie dla wszystkich $\tau$ obliczymy normę różnicy: $\norm{G - G_\tau}_1$. Wyniki tych obliczneń przedstawiamy na Tabeli~\ref{grad_fd_tbl}.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
      \hline
      $\tau$ & 10^{-3} & 10^{-4} & 10^{-5} & 10^{-6} & 10^{-7} & 10^{-8} & 10^{-9} & 10^{-10} \\
      \hline
      $\norm{G - G_\tau}_1$ & 444599.7 & 34471.1 & 357.2 & 3.6 & 0.5 & 4.7 & 54.0 & 384.5 \\
      \hline
    \end{tabular}
    \caption{Różnice wyników między naszą implementacją gradientu, a różnicami skończonymi.}\label{grad_fd_tbl}
  \end{center}
\end{table}

Zgodnie z oczekiwaniami gdy krok różnic skończonych $\tau$ maleje, to do pewnego momentu maleje też $\norm{G - G_\tau}_1$. W pewnym momencie norma ta zaczyna rosnąć wraz z dalszym zmniejszaniem $\tau$, co też jest zachowaniem oczekiwanym.

Warto tu jeszcze dodać, że liczba wywołań $\hat{J}$ podana na Tabeli~\ref{test_tbl} nie uwzględnia wywołań potrzebnych do aproksymacji gradientu metodą różnic skończonych. Aby policzyć pochodną dla jednego parametru potrzeba raz dodatkowo wywołać $\hat{J}$, więc jednorazowe policzenie gradientu wymaga tylu wywołań ile jest parametrów (w tym przypadku 51). Gradient jest liczony w każdej iteracji co daje łącznie $20\cdot 51 = 1020$ dodatkowych wywołań $\hat{J}$. Inną wadą przybliżania gradientu metodą różnic skończonych są błędy. Zauważmy, że w okolicy punktu przecięcia się krzywych $y_1$ i $y_2$ wartość i pochodna wyrażenia $G((y_2(t) - y_1(t))/\epsilon)$, gdzie $G(x) = \frac{1 + \tanh(x)}{2}$, zmienia się bardzo szybko w czasie, co powoduje znaczne błędy przy zbyt dużym kroku metody różnic skończonych, co możemy też zaobserwować na Tabeli~\ref{grad_fd_tbl}, w postaci dużej normy różnicy gradientów, gdy krok różnic skończonych to $10^{-3}$, czyli wartość domyślna w FMINICON użyta też do obliczenia wyników tego eksperymentu.

\subsubsection{Parametry (CC)}

\begin{table}[h]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      Parametry & algorytm & aproks. & siatka & $h$ & start & $\hat{J}$ & iter & $\#\hat{J}$ & $\norm{G}_1$ & $\frac{\norm{G_0}_1}{\norm{G}_1}$ \\
      \hline
      (CC) & {\it lm\/} & $P_0$ & $S_1$ & 0.1 & $g_0$ & 2.2 & 3 & 8 & 0.32 & 16.8 \\
      \hline
      (CC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 2.19 & 3 & 8 & 0.32 & 17.1 \\
      \hline
      (CC) & {\it lm\/} & $P_0$ & $N_{kon}$ & 0.1 & $g_0$ & 2.64 & 9 & 14 & 0.8 & 6.8 \\
      \hline
      (CC) & {\it lm\/} & $P_1$ & $S_1$ & 0.1 & $g_0$ & 2.21 & 2 & 7 & 0.33 & 16.3 \\
      \hline
      (CC) & {\it lm\/} & $P_1$ & $S_{0.5}$ & 0.1 & $g_0$ & 2.21 & 2 & 7 & 0.33 & 16.3 \\
      \hline
      (CC) & {\it lm\/} & $P_1$ & $N_{kon}$ & 0.1 & $g_0$ & 2.66 & 2 & 7 & 0.83 & 6.5 \\
      \hline
      (CC) & {\it lm\/} & $P_0$ & $S_1$ & 0.1 & $g_3$ & 2.14 & 1 & 2 & 0.26 & 1.0 \\
      \hline
      (CC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_3$ & 2.14 & 1 & 2 & 0.26 & 1.0 \\
      \hline
      (CC) & {\it lm\/} & $P_0$ & $N_{kon}$ & 0.1 & $g_3$ & 2.14 & 1 & 2 & 0.26 & 1.0 \\
      \hline
      (CC) & {\it lm\/} & $P_1$ & $S_1$ & 0.1 & $g_3$ & 2.14 & 1 & 2 & 0.26 & 1.0 \\
      \hline
      (CC) & {\it lm\/} & $P_1$ & $S_{0.5}$ & 0.1 & $g_3$ & 2.14 & 1 & 2 & 0.26 & 1.0 \\
      \hline
      (CC) & {\it lm\/} & $P_1$ & $N_{kon}$ & 0.1 & $g_3$ & 2.14 & 1 & 2 & 0.26 & 1.0 \\
      \hline
    \end{tabular}
    \caption{Eksperymenty z parametrami (CC) dla różnych wyborów aproksymacji, siatki i startu}\label{param1_tbl}
  \end{center}
\end{table}

\begin{figure}[h]
  \centering
  \includegraphics[width=.5\textwidth]{../plots/plot_max}
  \caption{Rozwiązanie dla parametrów (CC)}\label{max_plot}
\end{figure}

Wyniki dla parametrów (CC)\ są dość jednoznaczne. Najlepszym znalezionym rozwiązaniem jest $g \equiv g_{\max} = 3$, które zaprezentowano na Rysunku~\ref{max_plot}. Wszystkie testy zaczynające z tego sterowania zbiegły do niego po jednej iteracji, patrz Tabela~\ref{param1_tbl}. Widzimy też z tej tabeli, że testy korzystające z siatki niejednorodne wypadają zauważalnie gorzej od pozostałych, algorytm {\it sqp\/} jest jedynym który zbiegł z zerowego sterowania do sterowania optymalnego. Różnice między pozostałymi metodami są nieznaczne.

Jako, że najlepsze znalezione rozwiązanie dla tych parametrów jest dość proste, w dalszych eksperymentach skupimy się na parametrach~(DC)

\subsubsection{Metoda dyskretyzacji}

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      Parametry & algorytm & aproks. & siatka & $h$ & start & $\hat{J}$ & iter & $\#\hat{J}$ & $\norm{G}_1$ & $\frac{\norm{G_0}_1}{\norm{G}_1}$ \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.04 & 81 & 158 & 141.46 & 0.0 \\
      \hline
      (DC) & {\it lm\/} & $P_1$ & $S_{0.5}$ & 0.1 & $g_0$ & 2.94 & 95 & 185 & 23.69 & 0.1 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.3 & 18 & 205 & 32.34 & 0.1 \\
      \hline
      (DC) & {\it sqp\/} & $P_1$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.28 & 9 & 105 & 7.64 & 0.4 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 120 & 236 & 13.07 & 0.2 \\
      \hline
      (DC) & {\it lm\/} & $P_1$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.74 & 103 & 202 & 32.08 & 0.1 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 10 & 123 & 5.67 & 0.4 \\
      \hline
      (DC) & {\it sqp\/} & $P_1$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 10 & 136 & 4.47 & 0.5 \\
      \hline
    \end{tabular}
    \caption{Eksperymenty badające metodę dyskretyzacji}\label{discr_tbl}
  \end{center}
\end{table}

Porównując odpowiednie wartości Tabeli~\ref{discr_tbl}, możemy zaobserwować, że dla sterowania startowego $g_0$, dyskretyzacja $P_1$ osiąga zauważalnie lepsze rezultaty niż dyskretyzacja $P_0$. Dla algorytmu {\it lm\/} zastosowanie dyskretyzacji liniowej poprawiło wyniki, natomiast dla algorytmu {\it sqp\/} zmniejszyło zarówno liczbę iteracji jak i liczbę wywołań prawie dwukrotnie. Gdy punkt startowy to $g_{0.4,42.5}$, to obie dyskretyzacje osiągają bardzo podobne rezultaty.

\subsubsection{Siatka dyskretyzacji}

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      Parametry & algorytm & aproks. & siatka & $h$ & start & $\hat{J}$ & iter & $\#\hat{J}$ & $\norm{G}_1$ & $\frac{\norm{G_0}_1}{\norm{G}_1}$ \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_1$ & 0.1 & $g_0$ & 3.08 & 63 & 121 & 161.6 & 0.0 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.04 & 81 & 158 & 141.46 & 0.0 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $N_{sr}$ & 0.1 & $g_0$ & 3.02 & 25 & 51 & 7.09 & 0.4 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_1$ & 0.1 & $g_0$ & 3.16 & 14 & 164 & 63.94 & 0.0 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.3 & 18 & 205 & 32.34 & 0.1 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $N_{sr}$ & 0.1 & $g_0$ & 3.39 & 15 & 172 & 49.73 & 0.1 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_1$ & 0.1 & $g_{0.4,42.5}$ & 2.78 & 118 & 231 & 22.23 & 0.1 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 120 & 236 & 13.07 & 0.2 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $N_{sr}$ & 0.1 & $g_{0.4,42.5}$ & 2.76 & 48 & 96 & 74.96 & 0.0 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_1$ & 0.1 & $g_{0.4,42.5}$ & 4.07 & 24 & 85 & 0.13 & 16.9 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 10 & 123 & 5.67 & 0.4 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $N_{sr}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 8 & 104 & 4.55 & 0.5 \\
      \hline
    \end{tabular}
    \caption{Eksperymenty badające siatkę dyskretyzacji}\label{grid_tbl}
  \end{center}
\end{table}

Zauważmy, że dla algorytmu {\it lm\/} siatka dyskretyzacji nie ma zbyt dużego wpływu na końcowy wynik. Dla testów różniących się tylko siatką dyskretyzacji, różnica w wynikach dla algorytmu {\it lm\/} wynosi co najwyżej $0.09$. Możemy zauważyć, że zwykle wynik poprawia się wraz z zagęszczaniem siatki, ale jak widzimy dla startu $g_{0.4,42.5}$ i siatki $S_{0.1}$, zagęszczenie satki może pogorszyć wynik. Siatka nieregularna dla tego algorytmu nie osiągała najlepszych wyników, ale zbiegała znacznie szybciej niż siatki regularne o podobnych wynikach.

Dla algorytmu {\it sqp\/} i startu $g_0$ siatka dyskretyzacji ma już większe znaczenie, różnice wynoszą nawet $0.23$. Najlepszy wynik w tym przypadku osiąga siatka $S_1$, a siatka niejednorodna --- najgorszy. 

Wyniki dla algorytmu {\it sqp\/} siatki $S_1$ i startu $g_{0.4,42.5}$ są podejrzane. Wartość $\hat{J}$ dla sterowania startowego $g_{0.4,42.5}$ wynosi $30.1$, więc jest lepsza niż wynik. Sprawdzenie wyników dla wywołań pośrednich ujawniło, że algorytm w trakcie optymalizacji osiągał wyniki podobne jak pozostałe testy dla tego sterowania startowego. Takie zachowanie byłoby teoretycznie możliwe dla tego algorytmu, ponieważ nie wymaga on spełnienia ograniczeń w trakcie optymalizacji, więc mógłby nie znaleźć lepszego punktu spełniającego ograniczenia. Jednakże punkt startowy spełnia ograniczenia, więc zachowanie takie wydaje się błędem optymalizatora.

\subsubsection{Krok dyskretyzacji $h$}

\begin{table}[h]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      Parametry & algorytm & aproks. & siatka & $h$ & start & $\hat{J}$ & iter & $\#\hat{J}$ & $\norm{G}_1$ & $\frac{\norm{G_0}_1}{\norm{G}_1}$ \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.5 & $g_0$ & 3.12 & 79 & 156 & 1.98 & 1.5 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.04 & 81 & 158 & 141.46 & 0.0 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.02 & $g_0$ & 2.94 & 129 & 256 & 2.77 & 1.1 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.5 & $g_0$ & 3.28 & 8 & 92 & 13.11 & 0.2 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.3 & 18 & 205 & 32.34 & 0.1 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.02 & $g_0$ & 3.31 & 9 & 106 & 9.24 & 0.3 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.5 & $g_{0.4,42.5}$ & 2.75 & 83 & 159 & 192.7 & 0.0 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 120 & 236 & 13.07 & 0.2 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.02 & $g_{0.4,42.5}$ & 2.75 & 91 & 179 & 48.14 & 0.0 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.5 & $g_{0.4,42.5}$ & 2.75 & 10 & 127 & 6.17 & 0.4 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 10 & 123 & 5.67 & 0.4 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.02 & $g_{0.4,42.5}$ & 2.75 & 13 & 166 & 18.87 & 0.1 \\
      \hline
    \end{tabular}
    \caption{Eksperymenty badające krok dyskretyzacji $h$}\label{step_tbl}
  \end{center}
\end{table}

Krok dyskretyzacji, jak wnioskujemy z Tabeli~\ref{step_tbl}, dla algorytmu {\it lm\/} zachowuje się przewidywalnie, to znaczy im niższy, tym lepsze wyniki. Co ciekawe, dla algorytmu {\it sqp\/} zależność jest odwrotna, choć różnice w wynikach są dość nieznaczne (rzędu $0.03$). Dla sterowania startowego $g_{0.4,42.5}$ krok dyskretyzacji wydaje się nie mieć prawie żadnego wpływu na wynik.

\subsubsection{Sterowanie startowe}

\begin{table}[h]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      Parametry & algorytm & aproks. & siatka & $h$ & start & $\hat{J}$ & iter & $\#\hat{J}$ & $\norm{G}_1$ & $\frac{\norm{G_0}_1}{\norm{G}_1}$ \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.04 & 81 & 158 & 141.46 & 0.0 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_0$ & 3.3 & 18 & 205 & 32.34 & 0.1 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_3$ & 4.07 & 1 & 2 & 0.13 & 1.0 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_3$ & 4.07 & 1 & 2 & 0.13 & 1.0 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 120 & 236 & 13.07 & 0.2 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.4,42.5}$ & 2.75 & 10 & 123 & 5.67 & 0.4 \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.55,42.5}$ & 2.72 & 31 & 64 & 50.43 & 0.0 \\
      \hline
      (DC) & {\it sqp\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.55,42.5}$ & 2.71 & 10 & 130 & 3.63 & 0.6 \\
      \hline
    \end{tabular}
    \caption{Eksperymenty badające sterowanie startowe}\label{start_tbl}
  \end{center}
\end{table}

%h - the place, b - bottom, t - top 
\begin{figure}[h]
  \centering
  \includegraphics[width=.5\textwidth]{../plots/plot_param2_best}
  \caption{Rozwiązanie dla parametrów (DC)}\label{param2_best_sol}
\end{figure}

Jak mogliśmy się już przekonać na poprzednich eksperymentach i co potwierdzają wyniki z Tabeli~\ref{start_tbl}, dobór odpowiedniego sterowania startowego jest kluczowy.

Widzimy, że przy parametrach (DC), podobnie jak przy parametrach (CC), sterowanie $g_3$ (czyli stale równe $3 = g_{\max}$) wydaje się być minimum lokalnym, ale w tym przypadku znacznie gorszym od pozostałych rezultatów. Najlepsze wyniki osiągane są dla sterowania startowego $g_{0.55,42.5}$. Ciekawe wyniki wychodzą sterowania startowego $\mathfrak{g}$. Jest to bardziej skomplikowane sterowanie startowe niż pozostałe i nie osiąga zby dobrych wyników. Ponadto wymaga stosunkowo dużo iteracji i wywołań funkcji $\hat{J}$, szczególne dla algorytmu {\it sqp\/} który potrzebował aż 1065 wywołań w 100 iteracjach, co było ustawione jako maksymalna liczba iteracji dla tego algorytmu.

Najlepszy wynik to $2.71$ i osiągneliśmy go dla sterowania startowego $g_{0.55,42.5}$ i algorytmu {\it sqp}. Zaprezentowany jest on na Rysunku~\ref{param2_best_sol}.

\subsection{Większa dokładność optymalizacji}
Osiągane rozwiązania wydają się bardzo odległe od minimów lokalnych, co widzimy po wartościach $\norm{G}_1$ i $\frac{\norm{G_0}_1}{\norm{G}_1}$. Okazuje się, że proces optymalizacji jest przerywany przez optymalizator z powodu zbyt niewielkiej poprawy wartości $\hat{J}$ między iteracjami. Z tego powodu przeprowadzimy dodatkowe eksperymenty, w których zmienimy parametr tego warunku stopu (opcja ,,TolFun'' w FMINICON) z $10^{-6}$ na $10^{-9}$. Wartość tego parametru oznacza minimalną względną poprawę wartości funkcji celu. Na Tabeli~\ref{new_best_tbl} i Rysunku~\ref{new_best_sol} prezentujemy wyniki przeprowadzonego eksperymentu.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      Parametry & algorytm & aproks. & siatka & $h$ & start & $\hat{J}$ & iter & $\#\hat{J}$ & $\norm{G}_1$ & $\frac{\norm{G_0}_1}{\norm{G}_1}$ \\
      \hline
      (DC) & {\it lm\/} & $P_0$ & $S_{0.5}$ & 0.1 & $g_{0.55,42.5}$ & 2.69 & 412 & 722 & 0.79 & 2.6 \\
      \hline
    \end{tabular}
    \caption{Eksperyment z większą dokładnością}\label{new_best_tbl}
  \end{center}
\end{table}

\begin{figure}[h!]
  \centering
  \includegraphics[width=.5\textwidth]{../plots/plot_new_best}
  \caption{Rozwiązanie przy większej dokładności}\label{new_best_sol}
\end{figure}

Jak widzimy spowodowało to zauważalną poprawę wyników, zmianę w kształcie znalezionego sterowania, ale kosztem znacznego wzrostu czasu optymalizacji.

\section{Analiza i krytyka wyników}

Jak widzimy, wyniki dla różnych rodzajów parametrów znacznie się różnią. Dokładniejsze przyjrzenie się funkcjonałowi celu (\ref{objfsim}) pozwala wyjaśnić takie zjawisko. Jak widzimy parametr $\omega$ jest mnożony przez wartość drugiej całki. Zauważmy, że funkcja pod drugą całką jest gładkim przybliżeniem funkcji znaku wyrażenia $y_2(t) - y_1(t)$. W 2-gim zestawie parametrów parametr $\omega$ jest znacznie większy niż w 1-szym, więc w tym przypadku druga całka ma większy wpływ na wynik funkcjonału. Jak przyjrzymy się rozwiązaniu z Rysunku~\ref{param2_best_sol}, widzimy, że punkt nieciągłości znajduje się od razu po przecięciu się krzywych $y_1$ i $y_2$, a po nim sterowanie ma taką wartość aby krzywe te były bardzo blisko siebie, ale przy zachowaniu $y_2(t) - y_1(t) < 0$. Wygląda więc na to, przy parametrach (DC)\ bardziej opłaca się utrzymywać stan $y_2(t) - y_1(t) < 0$, natomiast przy parametrach (CC)\ lepsze wyniki daje minimalizacja pierwszej całki, czyli pola pod $y_1 + y_2$. Możemy się też spodziewać, że wysokie wartości sterowania powodują zmniejszanie się zarówno $y_1$ jak i $y_2$, ale od pewnej wartości sterowania $y_1$ maleje szybciej niż $y_2$. Taka hipoteza zgadzałaby się z interpretacją $y_1$ i $y_2$ jako liczba komórek rakowych odpowiednio podatnych na działanie leku i odpornych na niego, a wartości sterowania jako dawki leku.

\subsection{Krytyka wyników}
Wszystkie wyniki które udało się osiągnąć są minimami lokalnymi. Jak już zauważyliśmy, wyniki były mocno zależne od punktu startowego, nawet w przypadku algorytmu {\it sqp}, który powinien szukać rozwiązania bardziej globalnie. Być może zastosowanie innych algorytmów optymalizacji nieliniowej umożliwiłoby szukanie rozwiązania w sposób mniej zależący od znalezienia dobrego punktu startowego.

Niejednorodna siatka dyskretyzacji jest metodą nierzadko pozwalającą na poprawę tępa zbieżności, ale nie udało się jej tu z sukcesem zastosować. Podobnie przybliżanie sterowania za pomocą Solana wyższego rzędu też mogłoby poprawić tempo zbieżności. W literaturze rozważa też metody automatyzacji znajdowania siatki dyskretyzacji i odpowiedniego rzędu dyskretyzacji. Przykładem jest tu praca~\cite{Rao-ph}. Być może zastosowanie ich umożliwiłoby uzyskanie lepszych wyników.

Przypomnijmy jeszcze uwagę z początku pracy, że gdy $y_1 = y_2 = 0$, lub $y_3 = 0$ to zadanie nie jest dobrze określone, a w przypadku gdy wartości te są bliskie zeru, mogą występować znaczne błędy numeryczne. W żadnym eksperymencie wartości $y_1$ ani $y_2$ nie były bliskie zeru. Minimalna wartość $y_3$ z Rysunku~\ref{max_plot} to $14.9$, więc i ta nie jest zbyt bliska 0. Okazuje się jednak, że przy parametrach (DC), w rozwiązaniu (\ref{odesim}) dla sterowania stale równego $g_{\max}$ minimalna wartość $y_3$ wynosi ok. $0.02$, więc ten eksperyment może być obarczony istotnym błędem numerycznym.

\newpage{}
\bibliography{bibliography}{}
\bibliographystyle{abbrv}
\end{document}
